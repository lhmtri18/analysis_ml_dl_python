{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "import random\n",
    "np.random.seed(18)\n",
    "\n",
    "means= [[2,2],[8,3],[3,6]]\n",
    "cov=[[1,0],[0,1]]\n",
    "N=500 #number of data points in each clusters\n",
    "#random data points\n",
    "X0= np.random.multivariate_normal(means[0],cov,N)\n",
    "#np.mean(X0,axis=0) =>2,2\n",
    "X1= np.random.multivariate_normal(means[1],cov,N)\n",
    "#np.mean(X1,axis=0) =>8,3\n",
    "X2= np.random.multivariate_normal(means[2],cov,N)\n",
    "#np.mean(X2,axis=0) =>3,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.concatenate((X0,X1,X2),axis=0)\n",
    "K= 3#number of cluster\n",
    "original_label= np.asarray([0]*N+[1]*N+[2]*N).T#(0,0,0,...xN,1,1,1,...xN,2,2,2,...xN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_init_centroids(X,k):\n",
    "    return X[np.random.choice(X.shape[0],k,replace=False)]\n",
    "def kmeans_assign_labels(X,centroids):#find new labels\n",
    "    D= cdist(X,centroids)\n",
    "    return np.argmin(D,axis=1)#return index of minimum distance\n",
    "def has_converged (centroids, new_centroids):#return true if two set of centroids are the same\n",
    "    return set([tuple(a) for a in centroids])== set([tuple(a) for a in new_centroids])\n",
    "def kmeans_update_centroids(X,labels, K): #to update centroid when knowning labels of each data point\n",
    "    centroids= np.zeros((K,X.shape[1]))\n",
    "    for k in range(K):\n",
    "        #collect all points that assigned to k-th centroids\n",
    "        Xk= X[labels==k,:]\n",
    "        centroids[k,:]= np.mean(Xk, axis=0)\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 2)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X,K):\n",
    "    centroids= [kmeans_init_centroids(X,K)]#choose k data point in X to put as centroids\n",
    "    labels=[]\n",
    "    it=0\n",
    "    while True:\n",
    "        #shape centroids[-1] is (3,2)\n",
    "        labels.append(kmeans_assign_labels(X, centroids[-1])) #shape(1500,1)\n",
    "        new_centroids= kmeans_update_centroids(X, labels[-1],K)\n",
    "        if has_converged(centroids[-1],new_centroids):\n",
    "            break\n",
    "        centroids.append(new_centroids)\n",
    "        it+=1\n",
    "    return (centroids, labels, it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (1500, 2)\n",
      "l:  [[-1.74918676e-02 -8.22495947e-03]\n",
      " [ 2.07417695e+00  5.71528152e+00]\n",
      " [ 8.54599772e+00  2.33506316e+00]]\n"
     ]
    }
   ],
   "source": [
    "(centroids, labels, it)= kmeans(X,K)\n",
    "print('centroids found by out algorithm: \\n', centroids[-1])#get the last centroids,[-1]\n",
    "print('it:\\n',it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict new data [1 1 0]\n"
     ]
    }
   ],
   "source": [
    "#predict new data\n",
    "print('predict new data',kmeans_assign_labels(np.array([[2.3,4.6],[1.5,8.9],[4.6,0.]]), centroids[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([2.3,4.6]).reshape(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centroids found by sklearn: \n",
      "[[8.07476866 3.01494931]\n",
      " [3.02702878 5.95686115]\n",
      " [1.9834967  1.96588127]]\n",
      "predict label [1 2 2 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#use library\n",
    "from sklearn.cluster import KMeans\n",
    "model= KMeans(n_clusters=3, random_state=0).fit(X)\n",
    "print('centroids found by sklearn: ')\n",
    "print(model.cluster_centers_)\n",
    "pred_label= model.predict(X)\n",
    "print('predict label', pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "?KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function multivariate_normal:\n",
      "\n",
      "multivariate_normal(...) method of mtrand.RandomState instance\n",
      "    multivariate_normal(mean, cov[, size, check_valid, tol])\n",
      "    \n",
      "    Draw random samples from a multivariate normal distribution.\n",
      "    \n",
      "    The multivariate normal, multinormal or Gaussian distribution is a\n",
      "    generalization of the one-dimensional normal distribution to higher\n",
      "    dimensions.  Such a distribution is specified by its mean and\n",
      "    covariance matrix.  These parameters are analogous to the mean\n",
      "    (average or \"center\") and variance (standard deviation, or \"width,\"\n",
      "    squared) of the one-dimensional normal distribution.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    mean : 1-D array_like, of length N\n",
      "        Mean of the N-dimensional distribution.\n",
      "    cov : 2-D array_like, of shape (N, N)\n",
      "        Covariance matrix of the distribution. It must be symmetric and\n",
      "        positive-semidefinite for proper sampling.\n",
      "    size : int or tuple of ints, optional\n",
      "        Given a shape of, for example, ``(m,n,k)``, ``m*n*k`` samples are\n",
      "        generated, and packed in an `m`-by-`n`-by-`k` arrangement.  Because\n",
      "        each sample is `N`-dimensional, the output shape is ``(m,n,k,N)``.\n",
      "        If no shape is specified, a single (`N`-D) sample is returned.\n",
      "    check_valid : { 'warn', 'raise', 'ignore' }, optional\n",
      "        Behavior when the covariance matrix is not positive semidefinite.\n",
      "    tol : float, optional\n",
      "        Tolerance when checking the singular values in covariance matrix.\n",
      "        cov is cast to double before the check.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        The drawn samples, of shape *size*, if that was provided.  If not,\n",
      "        the shape is ``(N,)``.\n",
      "    \n",
      "        In other words, each entry ``out[i,j,...,:]`` is an N-dimensional\n",
      "        value drawn from the distribution.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The mean is a coordinate in N-dimensional space, which represents the\n",
      "    location where samples are most likely to be generated.  This is\n",
      "    analogous to the peak of the bell curve for the one-dimensional or\n",
      "    univariate normal distribution.\n",
      "    \n",
      "    Covariance indicates the level to which two variables vary together.\n",
      "    From the multivariate normal distribution, we draw N-dimensional\n",
      "    samples, :math:`X = [x_1, x_2, ... x_N]`.  The covariance matrix\n",
      "    element :math:`C_{ij}` is the covariance of :math:`x_i` and :math:`x_j`.\n",
      "    The element :math:`C_{ii}` is the variance of :math:`x_i` (i.e. its\n",
      "    \"spread\").\n",
      "    \n",
      "    Instead of specifying the full covariance matrix, popular\n",
      "    approximations include:\n",
      "    \n",
      "      - Spherical covariance (`cov` is a multiple of the identity matrix)\n",
      "      - Diagonal covariance (`cov` has non-negative elements, and only on\n",
      "        the diagonal)\n",
      "    \n",
      "    This geometrical property can be seen in two dimensions by plotting\n",
      "    generated data-points:\n",
      "    \n",
      "    >>> mean = [0, 0]\n",
      "    >>> cov = [[1, 0], [0, 100]]  # diagonal covariance\n",
      "    \n",
      "    Diagonal covariance means that points are oriented along x or y-axis:\n",
      "    \n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> x, y = np.random.multivariate_normal(mean, cov, 5000).T\n",
      "    >>> plt.plot(x, y, 'x')\n",
      "    >>> plt.axis('equal')\n",
      "    >>> plt.show()\n",
      "    \n",
      "    Note that the covariance matrix must be positive semidefinite (a.k.a.\n",
      "    nonnegative-definite). Otherwise, the behavior of this method is\n",
      "    undefined and backwards compatibility is not guaranteed.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Papoulis, A., \"Probability, Random Variables, and Stochastic\n",
      "           Processes,\" 3rd ed., New York: McGraw-Hill, 1991.\n",
      "    .. [2] Duda, R. O., Hart, P. E., and Stork, D. G., \"Pattern\n",
      "           Classification,\" 2nd ed., New York: Wiley, 2001.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> mean = (1, 2)\n",
      "    >>> cov = [[1, 0], [0, 1]]\n",
      "    >>> x = np.random.multivariate_normal(mean, cov, (3, 3))\n",
      "    >>> x.shape\n",
      "    (3, 3, 2)\n",
      "    \n",
      "    The following is probably true, given that 0.6 is roughly twice the\n",
      "    standard deviation:\n",
      "    \n",
      "    >>> list((x[0,0,:] - mean) < 0.6)\n",
      "    [True, True]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "help(np.random.multivariate_normal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
